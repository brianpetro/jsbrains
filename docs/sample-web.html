<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>JS Brains - Smart Chat Model - Universal Adapter Demo</title>
    <meta property="og:image" content="https://brianpetro.github.io/jsbrains/sample-web.gif">
    <style>
        :root {
            --lch-black: 0% 0 0;
            --lch-white: 100% 0 0;
            --lch-gray: 96% 0.005 96;
            --lch-gray-dark: 92% 0.005 96;
            --lch-gray-darker: 75% 0.005 96;
            --lch-blue: 54% 0.23 255;
            --lch-blue-light: 95% 0.03 255;
            --lch-blue-dark: 80% 0.08 255;
            --lch-red: 51% 0.2 31;
        }
        body {
            font-family: Arial, sans-serif;
            background-color: oklch(var(--lch-gray));
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            > div {
                display: flex;
            }
            > * {
                margin-bottom: 10px;
            }
        }
        h1, h2, p {
            margin: 0;
            text-align: center;
            margin-bottom: 10px;
        }
        p {
            line-height: 1.37;
            max-width: 60ch;
        }
        label {
            font-weight: bold;
            align-self: center;
        }
        input, select, button {
            padding: 2ch;
            border: 1px solid oklch(var(--lch-gray-dark));
            border-radius: 2ch;
            flex-grow: 1;
        }
        button {
            background-color: oklch(var(--lch-blue));
            color: white;
            border: none;
            cursor: pointer;
            &#send {
                max-width: 10ch;
                padding: 1ch 2ch;
                font-size: 2ch;
            }
            &:hover {
                background-color: oklch(var(--lch-blue-dark));
            }
        }
        #chat {
            width: 100%;
            max-width: 77ch;
            display: flex;
            flex-direction: column;
            align-items: flex-start;
            .msg {
                margin-bottom: 1ch;
                border: 1px solid oklch(var(--lch-gray-dark));
                padding: 2ch;
                border-radius: 2ch;
                background-color: white;
                max-width: 100ch;
                box-shadow: 0 0.2ch 0.4ch oklch(var(--lch-gray-dark));
                display: flex;
                justify-content: flex-start;
                &.user {
                    background-color: oklch(var(--lch-white));
                    align-self: end;
                }
                &.assistant {
                    background-color: oklch(var(--lch-blue-light));
                }
                &.notice {
                    color: oklch(var(--lch-red));
                }
            }
        }
        #input {
            width: 100%;
            max-width: 77ch;
        }
    </style>
</head>
<body>
    <h1>JS Brains - Smart Chat Model</h1>
    <h2>Universal Adapter Demo</h2>
    <p>A seriously simple sample app using JS Brains Smart Chat Model to interact with multiple LLMs in less than 200 lines of code.<br>You can find the source code for this app <a href="https://github.com/brianpetro/jsbrains/tree/main/smart-chat-model" target="_blank">here</a>.</p>
    <div>
        <label for="model-select">Model:</label>
        <select id="model-select">
            <!-- Options will be loaded dynamically -->
        </select>
    </div>
    <div>
        <label for="api-key">API Key:</label>
        <input type="password" id="api-key" placeholder="Enter your API key">
    </div>
    <div id="chat"></div>
    <div id="input">
        <input type="text" id="user-input" placeholder="Type your message here..." onkeydown="if (event.key === 'Enter') send_message()">
        <button id="send" onclick="send_message()">&gt;</button>
    </div>
    <script src="https://github.com/brianpetro/jsbrains/releases/download/0.0.1/smart_chat_model_web.js"></script>
    <script>
        const { SmartChatModel } = smart_chat_model;
        let chat_model;
        document.addEventListener('DOMContentLoaded', function() {
            const models = SmartChatModel.models;
            const model_selector = document.getElementById('model-select');
            for (const key in models) {
                if(key.startsWith('custom')) continue;
                const option = document.createElement('option');
                option.value = key;
                option.textContent = models[key].model_name + ' - ' + models[key].description;
                model_selector.appendChild(option);
            }
        });
        function init_chat_model() {
            const api_key = document.getElementById('api-key').value;
            const model_key = document.getElementById('model-select').value;
            const env = { chats: { current: { get_chat_ml: async () => ({ messages: [] }) } } };
            if (model_key.startsWith('anthropic')) new_msg('notice', `Anthropic prevents simple applications (those without a backend server) from accessing Claude. You can contact them to request they change this policy that goes against making AI accessible: <a href="https://docs.anthropic.com/claude/reference/need-support-contact-us" target="_blank">Contact Anthropic</a>`);
            else if (api_key === '') new_msg('notice', 'You must enter an API key to use this application.');
            else {
                document.getElementById('chat').innerHTML = '';
            }
            chat_model = new SmartChatModel(env, model_key, { api_key: api_key });
            chat_model.chunk_handler = (chunk) => {
                chunk = chunk.replace(/\n/g, '<br>');
                const last_msg = document.getElementById('chat').lastElementChild;
                if(last_msg && last_msg.classList.contains('user')) new_msg('assistant', chunk);
                else last_msg.innerHTML += chunk;
            };
            chat_model.done_handler = (final_response) => {
                final_response = final_response.replace(/\n/g, '<br>');
                const last_msg = document.getElementById('chat').lastElementChild;
                if(last_msg && last_msg.classList.contains('user')) new_msg('assistant', final_response);
                else last_msg.innerHTML = final_response;
            };
        }
        function new_msg(role, message) {
            const chat_container = document.getElementById('chat');
            const message_container = document.createElement('div');
            message_container.className = `msg ${role}`;
            message_container.innerHTML = `${message}`;
            chat_container.appendChild(message_container);
        }
        async function send_message() {
            if (!chat_model) init_chat_model(); // Initialize model on first send or when settings change
            const user_input = document.getElementById('user-input');
            const message = user_input.value;
            user_input.value = ''; // Clear input after sending
            new_msg('user', message);
            const req = {
                messages: [{ role: "user", content: message }],
                temperature: 0.3,
                max_tokens: 1000,
                stream: true
            };
            try {
                await chat_model.complete(req);
            } catch (error) {
                console.error('Error:', error);
                new_msg('notice', 'Failed to get response from the model. See console for details.');
            }
        }
        document.getElementById('api-key').addEventListener('change', init_chat_model);
        document.getElementById('model-select').addEventListener('change', init_chat_model);
    </script>
</body>
</html>