<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: smart-chat-model/adapters/anthropic.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: smart-chat-model/adapters/anthropic.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * AnthropicAdapter class provides methods to adapt the chat model interactions specifically for the Anthropic model.
 * It includes methods to prepare request bodies, count and estimate tokens, and handle tool calls and messages.
 */
class AnthropicAdapter {
  /**
   * Prepares the request body for the Anthropic API by converting ChatML format to a format compatible with Anthropic.
   * @param {Object} opts - The options object containing messages and other parameters in ChatML format.
   * @returns {Object} The request body formatted for the Anthropic API.
   */
  prepare_request_body(opts) { return chatml_to_anthropic(opts); }
  /**
   * Counts the tokens in the input by estimating them, as the Anthropic model does not provide a direct method.
   * @param {string|Object} input - The input text or object to count tokens in.
   * @returns {Promise&lt;number>} The estimated number of tokens in the input.
   */
  async count_tokens(input) {
    // Currently, the Anthropic model does not provide a way to count tokens
    return this.estimate_tokens(input);
  }
  /**
   * Estimates the number of tokens in the input based on a rough average token size.
   * @param {string|Object} input - The input text or object to estimate tokens in.
   * @returns {number} The estimated number of tokens.
   */
  estimate_tokens(input){
    if(typeof input === 'object') input = JSON.stringify(input);
    // Note: The division by 6 is a rough estimate based on observed average token size.
    return Math.ceil(input.length / 6); // Use Math.ceil for a more accurate count
  }
  /**
   * Extracts the first tool call from the JSON response content.
   * @param {Object} json - The JSON response from which to extract the tool call.
   * @returns {Object|null} The first tool call found, or null if none exist.
   */
  get_tool_call(json){
    return json.content.find(msg => msg.type === 'tool_use');
  }
  /**
   * Retrieves the input content of a tool call.
   * @param {Object} tool_call - The tool call object from which to extract the input.
   * @returns {Object} The input of the tool call.
   */
  get_tool_call_content(tool_call){
    return tool_call.input;
  }
  /**
   * Retrieves the name of the tool from a tool call object.
   * @param {Object} tool_call - The tool call object from which to extract the name.
   * @returns {string} The name of the tool.
   */
  get_tool_name(tool_call){
    return tool_call.name;
  }
  /**
   * Extracts the first message from the JSON response content.
   * @param {Object} json - The JSON response from which to extract the message.
   * @returns {Object|null} The first message found, or null if none exist.
   */
  get_message(json){ return json.content?.[0]; }
  /**
   * Retrieves the content of the first message from the JSON response.
   * @param {Object} json - The JSON response from which to extract the message content.
   * @returns {string|null} The content of the first message, or null if no message is found.
   */
  get_message_content(json) { return this.get_message(json)?.[this.get_message(json)?.type]; }
}
exports.AnthropicAdapter = AnthropicAdapter;
// https://docs.anthropic.com/claude/reference/messages_post
/**
 * Convert a ChatML object to an Anthropic object
 * @param {Object} opts - The ChatML object
 * @description This function converts a ChatML object to an Anthropic object. It filters out system messages and adds a system message prior to the last user message.
 * @returns {Object} - The Anthropic object
 */
function chatml_to_anthropic(opts) {
  let tool_counter = 0;
  const messages = opts.messages
    .filter(msg => msg.role !== 'system')
    .map(m => {
      if(m.role === 'tool'){
        return { role: 'user', content: [
          {
            type: 'tool_result',
            tool_use_id: `tool-${tool_counter}`,
            content: m.content
          }
        ]};
      }
      if(m.role === 'assistant' &amp;&amp; m.tool_calls){
        tool_counter++;
        const out = {
          role: m.role, 
          content: m.tool_calls.map(c => ({
            type: 'tool_use',
            id: `tool-${tool_counter}`,
            name: c.function.name,
            input: (typeof c.function.arguments === 'string') ? JSON.parse(c.function.arguments) : c.function.arguments
          }))
        };
        if(m.content){
          if(typeof m.content === 'string') out.content.push({type: 'text', text: m.content});
          else m.content.forEach(c => out.content.push(c));
        }
        return out;
      }
      if(typeof m.content === 'string') return { role: m.role, content: m.content };
      if(Array.isArray(m.content)){
        const content = m.content.map(c => {
          if(c.type === 'text') return {type: 'text', text: c.text};
          if(c.type === 'image_url'){
            const image_url = c.image_url.url;
            let media_type = image_url.split(":")[1].split(";")[0];
            if(media_type === 'image/jpg') media_type = 'image/jpeg';
            return {type: 'image', source: {type: 'base64', media_type: media_type, data: image_url.split(",")[1]}};
          }
        });
        return { role: m.role, content };
      }
      return m;
    })
  ;
  const { model, max_tokens, temperature, tools, tool_choice } = opts;
  // DO: handled better (Smart Connections specific)
  // get index of last system message
  const last_system_idx = opts.messages.findLastIndex(msg => msg.role === 'system' &amp;&amp; msg.content.includes('---BEGIN'));
  if (last_system_idx > -1) {
    const system_prompt = '&lt;context>\n' + opts.messages[last_system_idx].content + '\n&lt;/context>\n';
    messages[messages.length - 1].content = system_prompt + messages[messages.length - 1].content;
  }
  console.log(messages);
  const out = {
    messages,
    model,
    max_tokens,
    temperature,
  }
  if(tools){
    out.tools = tools.map(tool => ({
      name: tool.function.name,
      description: tool.function.description,
      input_schema: tool.function.parameters,
    }));
    if(tool_choice?.type === 'function'){
      // add "Use the ${tool.name} tool" to the last user message
      const tool_prompt = `Use the "${tool_choice.function.name}" tool!`;
      const last_user_idx = out.messages.findLastIndex(msg => msg.role === 'user');
      out.messages[last_user_idx].content += '\n' + tool_prompt;
      out.system = `Required: use the "${tool_choice.function.name}" tool!`;
    }
  }
  // DO: handled better (Smart Connections specific)
  // if system message exists prior to last_system_idx AND does not include "---BEGIN" then add to body.system
  const last_non_context_system_idx = opts.messages.findLastIndex(msg => msg.role === 'system' &amp;&amp; !msg.content.includes('---BEGIN'));
  if(last_non_context_system_idx > -1) out.system = opts.messages[last_non_context_system_idx].content;
  return out;
}
exports.chatml_to_anthropic = chatml_to_anthropic;

</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="AnthropicAdapter.html">AnthropicAdapter</a></li><li><a href="Book.html">Book</a></li><li><a href="CanvasAdapter.html">CanvasAdapter</a></li><li><a href="CohereAdapter.html">CohereAdapter</a></li><li><a href="Collection.html">Collection</a></li><li><a href="CollectionItem.html">CollectionItem</a></li><li><a href="FsAdapter.html">FsAdapter</a></li><li><a href="GeminiAdapter.html">GeminiAdapter</a></li><li><a href="LongTermMemory.html">LongTermMemory</a></li><li><a href="MarkdownAdapter.html">MarkdownAdapter</a></li><li><a href="ObsAJSON.html">ObsAJSON</a></li><li><a href="ObsMultiAJSON.html">ObsMultiAJSON</a></li><li><a href="ObsidianAJSON.html">ObsidianAJSON</a></li><li><a href="ObsidianAdapter.html">ObsidianAdapter</a></li><li><a href="ScMultiAJSON.html">ScMultiAJSON</a></li><li><a href="SmartChatAdapters.html">SmartChatAdapters</a></li><li><a href="SmartChatMD.html">SmartChatMD</a></li><li><a href="SmartChatModel.html">SmartChatModel</a></li><li><a href="SmartChats.html">SmartChats</a></li><li><a href="SmartChatsUI.html">SmartChatsUI</a></li><li><a href="SmartMarkdown.html">SmartMarkdown</a></li></ul><h3>Global</h3><ul><li><a href="global.html#add">add</a></li><li><a href="global.html#chat_ml_to_markdown">chat_ml_to_markdown</a></li><li><a href="global.html#chatml_to_anthropic">chatml_to_anthropic</a></li><li><a href="global.html#chatml_to_cohere">chatml_to_cohere</a></li><li><a href="global.html#chatml_to_gemini">chatml_to_gemini</a></li><li><a href="global.html#collection_instance_name_from">collection_instance_name_from</a></li><li><a href="global.html#cos_sim">cos_sim</a></li><li><a href="global.html#create_uid">create_uid</a></li><li><a href="global.html#deep_merge">deep_merge</a></li><li><a href="global.html#is_valid_tool_call">is_valid_tool_call</a></li><li><a href="global.html#markdown_to_chat_ml">markdown_to_chat_ml</a></li><li><a href="global.html#sequential_async_processor">sequential_async_processor</a></li><li><a href="global.html#sleep">sleep</a></li><li><a href="global.html#subtract">subtract</a></li><li><a href="global.html#top_acc">top_acc</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.3</a> on Sun Jul 14 2024 16:22:01 GMT+0000 (Coordinated Universal Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
